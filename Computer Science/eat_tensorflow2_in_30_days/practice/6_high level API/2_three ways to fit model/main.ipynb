{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1600753171745",
   "display_name": "Python 3.7.9 64-bit ('TrajDetec': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import * \n",
    "\n",
    "#打印时间分割线\n",
    "@tf.function\n",
    "def printbar():\n",
    "    today_ts = tf.timestamp()%(24*60*60)\n",
    "\n",
    "    hour = tf.cast(today_ts//3600+8,tf.int32)%tf.constant(24)\n",
    "    minite = tf.cast((today_ts%3600)//60,tf.int32)\n",
    "    second = tf.cast(tf.floor(today_ts%60),tf.int32)\n",
    "    \n",
    "    def timeformat(m):\n",
    "        if tf.strings.length(tf.strings.format(\"{}\",m))==1:\n",
    "            return(tf.strings.format(\"0{}\",m))\n",
    "        else:\n",
    "            return(tf.strings.format(\"{}\",m))\n",
    "    \n",
    "    timestring = tf.strings.join([timeformat(hour),timeformat(minite),\n",
    "                timeformat(second)],separator = \":\")\n",
    "    tf.print(\"==========\"*8+timestring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters.npz\n2113536/2110848 [==============================] - 3s 1us/step\n"
    }
   ],
   "source": [
    "MAX_LEN = 300\n",
    "BATCH_SIZE = 32\n",
    "(x_train,y_train),(x_test,y_test) = datasets.reuters.load_data()\n",
    "x_train = preprocessing.sequence.pad_sequences(x_train,maxlen=MAX_LEN)\n",
    "x_test = preprocessing.sequence.pad_sequences(x_test,maxlen=MAX_LEN)\n",
    "\n",
    "MAX_WORDS = x_train.max()+1\n",
    "CAT_NUM = y_train.max()+1\n",
    "\n",
    "ds_train = tf.data.Dataset.from_tensor_slices((x_train,y_train)) \\\n",
    "          .shuffle(buffer_size = 1000).batch(BATCH_SIZE) \\\n",
    "          .prefetch(tf.data.experimental.AUTOTUNE).cache()\n",
    "   \n",
    "ds_test = tf.data.Dataset.from_tensor_slices((x_test,y_test)) \\\n",
    "          .shuffle(buffer_size = 1000).batch(BATCH_SIZE) \\\n",
    "          .prefetch(tf.data.experimental.AUTOTUNE).cache()"
   ]
  },
  {
   "source": [
    "## 一，内置fit方法"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding (Embedding)        (None, 300, 7)            216874    \n_________________________________________________________________\nconv1d (Conv1D)              (None, 296, 64)           2304      \n_________________________________________________________________\nmax_pooling1d (MaxPooling1D) (None, 148, 64)           0         \n_________________________________________________________________\nconv1d_1 (Conv1D)            (None, 146, 32)           6176      \n_________________________________________________________________\nmax_pooling1d_1 (MaxPooling1 (None, 73, 32)            0         \n_________________________________________________________________\nflatten (Flatten)            (None, 2336)              0         \n_________________________________________________________________\ndense (Dense)                (None, 46)                107502    \n=================================================================\nTotal params: 332,856\nTrainable params: 332,856\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "def create_model():\n",
    "    \n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Embedding(MAX_WORDS,7,input_length=MAX_LEN))\n",
    "    model.add(layers.Conv1D(filters = 64,kernel_size = 5,activation = \"relu\"))\n",
    "    model.add(layers.MaxPool1D(2))\n",
    "    model.add(layers.Conv1D(filters = 32,kernel_size = 3,activation = \"relu\"))\n",
    "    model.add(layers.MaxPool1D(2))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(CAT_NUM,activation = \"softmax\"))\n",
    "    return(model)\n",
    "\n",
    "def compile_model(model):\n",
    "    model.compile(optimizer=optimizers.Nadam(),\n",
    "                loss=losses.SparseCategoricalCrossentropy(),\n",
    "                metrics=[metrics.SparseCategoricalAccuracy(),metrics.SparseTopKCategoricalAccuracy(5)]) \n",
    "    return(model)\n",
    " \n",
    "model = create_model()\n",
    "model.summary()\n",
    "model = compile_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train for 281 steps, validate for 71 steps\nEpoch 1/10\n281/281 [==============================] - 5s 19ms/step - loss: 1.9726 - sparse_categorical_accuracy: 0.4861 - sparse_top_k_categorical_accuracy: 0.7483 - val_loss: 1.6466 - val_sparse_categorical_accuracy: 0.5757 - val_sparse_top_k_categorical_accuracy: 0.7636\nEpoch 2/10\n281/281 [==============================] - 2s 7ms/step - loss: 1.4314 - sparse_categorical_accuracy: 0.6280 - sparse_top_k_categorical_accuracy: 0.8053 - val_loss: 1.5296 - val_sparse_categorical_accuracy: 0.6140 - val_sparse_top_k_categorical_accuracy: 0.7939\nEpoch 3/10\n281/281 [==============================] - 2s 7ms/step - loss: 1.1630 - sparse_categorical_accuracy: 0.6941 - sparse_top_k_categorical_accuracy: 0.8578 - val_loss: 1.5623 - val_sparse_categorical_accuracy: 0.6287 - val_sparse_top_k_categorical_accuracy: 0.8059\nEpoch 4/10\n281/281 [==============================] - 2s 6ms/step - loss: 0.8999 - sparse_categorical_accuracy: 0.7640 - sparse_top_k_categorical_accuracy: 0.9107 - val_loss: 1.7315 - val_sparse_categorical_accuracy: 0.6336 - val_sparse_top_k_categorical_accuracy: 0.8014\nEpoch 5/10\n281/281 [==============================] - 2s 6ms/step - loss: 0.6729 - sparse_categorical_accuracy: 0.8280 - sparse_top_k_categorical_accuracy: 0.9479 - val_loss: 1.9816 - val_sparse_categorical_accuracy: 0.6358 - val_sparse_top_k_categorical_accuracy: 0.7983\nEpoch 6/10\n281/281 [==============================] - 2s 6ms/step - loss: 0.5126 - sparse_categorical_accuracy: 0.8749 - sparse_top_k_categorical_accuracy: 0.9695 - val_loss: 2.2422 - val_sparse_categorical_accuracy: 0.6313 - val_sparse_top_k_categorical_accuracy: 0.8014\nEpoch 7/10\n281/281 [==============================] - 2s 7ms/step - loss: 0.4078 - sparse_categorical_accuracy: 0.9018 - sparse_top_k_categorical_accuracy: 0.9817 - val_loss: 2.5108 - val_sparse_categorical_accuracy: 0.6322 - val_sparse_top_k_categorical_accuracy: 0.7988\nEpoch 8/10\n281/281 [==============================] - 2s 6ms/step - loss: 0.3395 - sparse_categorical_accuracy: 0.9188 - sparse_top_k_categorical_accuracy: 0.9876 - val_loss: 2.7594 - val_sparse_categorical_accuracy: 0.6305 - val_sparse_top_k_categorical_accuracy: 0.7983\nEpoch 9/10\n281/281 [==============================] - 2s 7ms/step - loss: 0.2931 - sparse_categorical_accuracy: 0.9315 - sparse_top_k_categorical_accuracy: 0.9909 - val_loss: 3.0278 - val_sparse_categorical_accuracy: 0.6202 - val_sparse_top_k_categorical_accuracy: 0.7961\nEpoch 10/10\n281/281 [==============================] - 2s 6ms/step - loss: 0.2589 - sparse_categorical_accuracy: 0.9390 - sparse_top_k_categorical_accuracy: 0.9931 - val_loss: 3.2984 - val_sparse_categorical_accuracy: 0.6153 - val_sparse_top_k_categorical_accuracy: 0.7903\n"
    }
   ],
   "source": [
    "history = model.fit(ds_train,validation_data = ds_test,epochs = 10)"
   ]
  },
  {
   "source": [
    "## 二，内置train_on_batch方法"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding (Embedding)        (None, 300, 7)            216874    \n_________________________________________________________________\nconv1d (Conv1D)              (None, 296, 64)           2304      \n_________________________________________________________________\nmax_pooling1d (MaxPooling1D) (None, 148, 64)           0         \n_________________________________________________________________\nconv1d_1 (Conv1D)            (None, 146, 32)           6176      \n_________________________________________________________________\nmax_pooling1d_1 (MaxPooling1 (None, 73, 32)            0         \n_________________________________________________________________\nflatten (Flatten)            (None, 2336)              0         \n_________________________________________________________________\ndense (Dense)                (None, 46)                107502    \n=================================================================\nTotal params: 332,856\nTrainable params: 332,856\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "def create_model():\n",
    "    model = models.Sequential()\n",
    "\n",
    "    model.add(layers.Embedding(MAX_WORDS,7,input_length=MAX_LEN))\n",
    "    model.add(layers.Conv1D(filters = 64,kernel_size = 5,activation = \"relu\"))\n",
    "    model.add(layers.MaxPool1D(2))\n",
    "    model.add(layers.Conv1D(filters = 32,kernel_size = 3,activation = \"relu\"))\n",
    "    model.add(layers.MaxPool1D(2))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(CAT_NUM,activation = \"softmax\"))\n",
    "    return(model)\n",
    "\n",
    "def compile_model(model):\n",
    "    model.compile(optimizer=optimizers.Nadam(),\n",
    "                loss=losses.SparseCategoricalCrossentropy(),\n",
    "                metrics=[metrics.SparseCategoricalAccuracy(),metrics.SparseTopKCategoricalAccuracy(5)]) \n",
    "    return(model)\n",
    " \n",
    "model = create_model()\n",
    "model.summary()\n",
    "model = compile_model(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,ds_train,ds_valid,epoches):\n",
    "\n",
    "    for epoch in tf.range(1,epoches+1):\n",
    "        model.reset_metrics()\n",
    "        \n",
    "        # 在后期降低学习率\n",
    "        if epoch == 5:\n",
    "            model.optimizer.lr.assign(model.optimizer.lr/2.0)\n",
    "            tf.print(\"Lowering optimizer Learning Rate...\\n\\n\")\n",
    "        \n",
    "        for x, y in ds_train:\n",
    "            train_result = model.train_on_batch(x, y)\n",
    "\n",
    "        for x, y in ds_valid:\n",
    "            valid_result = model.test_on_batch(x, y,reset_metrics=False)\n",
    "            \n",
    "        if epoch%1 ==0:\n",
    "            printbar()\n",
    "            tf.print(\"epoch = \",epoch)\n",
    "            print(\"train:\",dict(zip(model.metrics_names,train_result)))\n",
    "            print(\"valid:\",dict(zip(model.metrics_names,valid_result)))\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "================================================================================13:44:01\nepoch =  1\ntrain: {'loss': 1.5183109, 'sparse_categorical_accuracy': 0.54545456, 'sparse_top_k_categorical_accuracy': 0.77272725}\nvalid: {'loss': 2.453667, 'sparse_categorical_accuracy': 0.5703473, 'sparse_top_k_categorical_accuracy': 0.7613535}\n\n================================================================================13:44:02\nepoch =  2\ntrain: {'loss': 1.0983586, 'sparse_categorical_accuracy': 0.72727275, 'sparse_top_k_categorical_accuracy': 0.8636364}\nvalid: {'loss': 2.19265, 'sparse_categorical_accuracy': 0.6148709, 'sparse_top_k_categorical_accuracy': 0.7934105}\n\n================================================================================13:44:04\nepoch =  3\ntrain: {'loss': 0.8068676, 'sparse_categorical_accuracy': 0.8181818, 'sparse_top_k_categorical_accuracy': 0.90909094}\nvalid: {'loss': 1.7307795, 'sparse_categorical_accuracy': 0.63401604, 'sparse_top_k_categorical_accuracy': 0.8009795}\n\n================================================================================13:44:06\nepoch =  4\ntrain: {'loss': 0.66921914, 'sparse_categorical_accuracy': 0.77272725, 'sparse_top_k_categorical_accuracy': 0.90909094}\nvalid: {'loss': 1.2761933, 'sparse_categorical_accuracy': 0.6353517, 'sparse_top_k_categorical_accuracy': 0.8009795}\n\nLowering optimizer Learning Rate...\n\n\n================================================================================13:44:08\nepoch =  5\ntrain: {'loss': 0.48707974, 'sparse_categorical_accuracy': 0.8181818, 'sparse_top_k_categorical_accuracy': 0.95454544}\nvalid: {'loss': 0.85889894, 'sparse_categorical_accuracy': 0.63401604, 'sparse_top_k_categorical_accuracy': 0.80187}\n\n================================================================================13:44:10\nepoch =  6\ntrain: {'loss': 0.41038123, 'sparse_categorical_accuracy': 0.90909094, 'sparse_top_k_categorical_accuracy': 0.95454544}\nvalid: {'loss': 0.6238954, 'sparse_categorical_accuracy': 0.63312554, 'sparse_top_k_categorical_accuracy': 0.80231524}\n\n================================================================================13:44:12\nepoch =  7\ntrain: {'loss': 0.33662882, 'sparse_categorical_accuracy': 0.90909094, 'sparse_top_k_categorical_accuracy': 0.95454544}\nvalid: {'loss': 0.50954473, 'sparse_categorical_accuracy': 0.63089937, 'sparse_top_k_categorical_accuracy': 0.80008906}\n\n================================================================================13:44:14\nepoch =  8\ntrain: {'loss': 0.27891544, 'sparse_categorical_accuracy': 0.90909094, 'sparse_top_k_categorical_accuracy': 0.95454544}\nvalid: {'loss': 0.4985188, 'sparse_categorical_accuracy': 0.626447, 'sparse_top_k_categorical_accuracy': 0.8045414}\n\n================================================================================13:44:16\nepoch =  9\ntrain: {'loss': 0.23965296, 'sparse_categorical_accuracy': 0.90909094, 'sparse_top_k_categorical_accuracy': 1.0}\nvalid: {'loss': 0.5435675, 'sparse_categorical_accuracy': 0.6251113, 'sparse_top_k_categorical_accuracy': 0.8009795}\n\n================================================================================13:44:17\nepoch =  10\ntrain: {'loss': 0.21687406, 'sparse_categorical_accuracy': 0.95454544, 'sparse_top_k_categorical_accuracy': 1.0}\nvalid: {'loss': 0.59430295, 'sparse_categorical_accuracy': 0.6251113, 'sparse_top_k_categorical_accuracy': 0.8009795}\n\n"
    }
   ],
   "source": [
    "train_model(model,ds_train,ds_test,10)"
   ]
  },
  {
   "source": [
    "## 三，自定义训练循环"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding (Embedding)        (None, 300, 7)            216874    \n_________________________________________________________________\nconv1d (Conv1D)              (None, 296, 64)           2304      \n_________________________________________________________________\nmax_pooling1d (MaxPooling1D) (None, 148, 64)           0         \n_________________________________________________________________\nconv1d_1 (Conv1D)            (None, 146, 32)           6176      \n_________________________________________________________________\nmax_pooling1d_1 (MaxPooling1 (None, 73, 32)            0         \n_________________________________________________________________\nflatten (Flatten)            (None, 2336)              0         \n_________________________________________________________________\ndense (Dense)                (None, 46)                107502    \n=================================================================\nTotal params: 332,856\nTrainable params: 332,856\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "def create_model():\n",
    "    \n",
    "    model = models.Sequential()\n",
    "\n",
    "    model.add(layers.Embedding(MAX_WORDS,7,input_length=MAX_LEN))\n",
    "    model.add(layers.Conv1D(filters = 64,kernel_size = 5,activation = \"relu\"))\n",
    "    model.add(layers.MaxPool1D(2))\n",
    "    model.add(layers.Conv1D(filters = 32,kernel_size = 3,activation = \"relu\"))\n",
    "    model.add(layers.MaxPool1D(2))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(CAT_NUM,activation = \"softmax\"))\n",
    "    return(model)\n",
    "\n",
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "================================================================================13:50:57\nEpoch=1,Loss:2.04555941,Accuracy:0.459029168,Valid Loss:1.74900675,Valid Accuracy:0.553873539\n\n================================================================================13:50:58\nEpoch=2,Loss:1.52538884,Accuracy:0.603985727,Valid Loss:1.55278289,Valid Accuracy:0.607301891\n\n================================================================================13:51:00\nEpoch=3,Loss:1.22206712,Accuracy:0.675462,Valid Loss:1.49989986,Valid Accuracy:0.641585052\n\n================================================================================13:51:01\nEpoch=4,Loss:0.895000041,Accuracy:0.765865088,Valid Loss:1.59119236,Valid Accuracy:0.651825488\n\n================================================================================13:51:02\nEpoch=5,Loss:0.611382246,Accuracy:0.842908,Valid Loss:1.80687654,Valid Accuracy:0.650935\n\n================================================================================13:51:03\nEpoch=6,Loss:0.439952,Accuracy:0.892228901,Valid Loss:2.03107119,Valid Accuracy:0.646482646\n\n================================================================================13:51:04\nEpoch=7,Loss:0.344299257,Accuracy:0.916833639,Valid Loss:2.20147157,Valid Accuracy:0.645592153\n\n================================================================================13:51:05\nEpoch=8,Loss:0.28612572,Accuracy:0.929637074,Valid Loss:2.33271599,Valid Accuracy:0.643811226\n\n================================================================================13:51:06\nEpoch=9,Loss:0.248984069,Accuracy:0.939100444,Valid Loss:2.44264674,Valid Accuracy:0.641585052\n\n================================================================================13:51:07\nEpoch=10,Loss:0.223363534,Accuracy:0.94244045,Valid Loss:2.54062223,Valid Accuracy:0.639804125\n\n"
    }
   ],
   "source": [
    "optimizer = optimizers.Nadam()\n",
    "loss_func = losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "train_loss = metrics.Mean(name='train_loss')\n",
    "train_metric = metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "valid_loss = metrics.Mean(name='valid_loss')\n",
    "valid_metric = metrics.SparseCategoricalAccuracy(name='valid_accuracy')\n",
    "\n",
    "@tf.function\n",
    "def train_step(model, features, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(features,training = True)\n",
    "        loss = loss_func(labels, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    train_loss.update_state(loss)\n",
    "    train_metric.update_state(labels, predictions)\n",
    "    \n",
    "\n",
    "@tf.function\n",
    "def valid_step(model, features, labels):\n",
    "    predictions = model(features)\n",
    "    batch_loss = loss_func(labels, predictions)\n",
    "    valid_loss.update_state(batch_loss)\n",
    "    valid_metric.update_state(labels, predictions)\n",
    "    \n",
    "\n",
    "def train_model(model,ds_train,ds_valid,epochs):\n",
    "    for epoch in tf.range(1,epochs+1):\n",
    "        \n",
    "        for features, labels in ds_train:\n",
    "            train_step(model,features,labels)\n",
    "\n",
    "        for features, labels in ds_valid:\n",
    "            valid_step(model,features,labels)\n",
    "\n",
    "        logs = 'Epoch={},Loss:{},Accuracy:{},Valid Loss:{},Valid Accuracy:{}'\n",
    "        \n",
    "        if epoch%1 ==0:\n",
    "            printbar()\n",
    "            tf.print(tf.strings.format(logs,\n",
    "            (epoch,train_loss.result(),train_metric.result(),valid_loss.result(),valid_metric.result())))\n",
    "            tf.print(\"\")\n",
    "            \n",
    "        train_loss.reset_states()\n",
    "        valid_loss.reset_states()\n",
    "        train_metric.reset_states()\n",
    "        valid_metric.reset_states()\n",
    "\n",
    "train_model(model,ds_train,ds_test,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}